{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cmr_strain_synchrony_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4GesjvqwaYhc",
        "5rfzS_VaxXGo",
        "Rf63PFMFojVa",
        "AvWVvi4_xb1k",
        "VWcJnrMxyC99",
        "7Z-HJGMGym2Z",
        "o60WSrIpzJbZ",
        "eO3oECWbzZOm",
        "HvRcs7ZZ2-Mv",
        "SxCV0-8SNWtg",
        "QR1dvsbWzJba",
        "kwODM948su1e"
      ],
      "authorship_tag": "ABX9TyP7f4EOYslRJn6SSeDjsMzD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfpva/cmr_strain_synchrony_analysis/blob/main/cmr_strain_synchrony_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WID2ZBhJKRNc"
      },
      "source": [
        "# CMR Strain Synchrony Analysis \n",
        "\n",
        "Perform sychrony analysis on regional strain curves in scientific reports from Circle cvi42.\n",
        "\n",
        "Based on methods described in \n",
        "> Balasubramanian S, Harrild DM, Kerur B, Marcus E, del Nido P, Geva T, Powell AJ. Impact of surgical pulmonary valve replacement on ventricular strain and synchrony in patients with repaired tetralogy of Fallot: a cardiovascular magnetic resonance feature tracking study. J Cardiovasc Magn Reson 2018 201. 2018;20(1):1–11. DOI: [10.1186/S12968-018-0460-0](https://doi.org/10.1186/S12968-018-0460-0)\n",
        "\n",
        "Code repository: [github.com/jfpva/cmr_strain_synchrony_analysis](https://github.com/jfpva/cmr_strain_synchrony_analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZVnJmRnKcuq"
      },
      "source": [
        "## Upload Data\n",
        "\n",
        "***user input required***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jmqUhcxJuQ7"
      },
      "source": [
        "# based on example in https://colab.research.google.com/notebooks/io.ipynb#scrollTo=vz-jH8T_Uk2c\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('Uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GesjvqwaYhc"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsHZO6b36lhX"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import codecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rfzS_VaxXGo"
      },
      "source": [
        "## Define Local Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf63PFMFojVa"
      },
      "source": [
        "### Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ah7ISDdooRV"
      },
      "source": [
        "def parse_data(filename,tablename,ventriclename='Left Ventricle'):\n",
        "  \"\"\"Parse regional strain data in Circle cvi42 scietific report.\n",
        "\n",
        "    Parameters:\n",
        "      filename (str): name of .txt file with source data\n",
        "      tablename (str): name of table of regional strain values to parse\n",
        "      ventriclename (str): either 'Left Ventricle' or 'Right Ventricle'\n",
        "\n",
        "    Returns:\n",
        "      data (dict): dictionary of parsed data with following keys\n",
        "        'Filename' (str): name of source data file\n",
        "        'Description' (str): name of table of regional strain\n",
        "        'Time' (list of int:): timing of strain curves\n",
        "        'Strain' (list of list of floats): strain curves for each regional segment\n",
        "  \"\"\"\n",
        "\n",
        "  data = {}\n",
        "\n",
        "  # open file, read in and clean up text\n",
        "  doc = codecs.open(filename, 'rU', 'latin1')\n",
        "  d = csv.reader((x.replace('\\x00', '') for x in doc), delimiter=\"\\t\")\n",
        "  rawvals_list = []\n",
        "  for row in d:\n",
        "    rawvals_list.append(row)\n",
        "  rawvals_list = [x for x in rawvals_list if x != []]\n",
        "\n",
        "  # filename of source data\n",
        "  data['Filename'] = filename\n",
        "\n",
        "  # search through raw data and extra table of interest\n",
        "  for i in range(len(rawvals_list)):\n",
        "    if rawvals_list[i][0].startswith(ventriclename) and len(rawvals_list[i])>1:\n",
        "      if rawvals_list[i][1].startswith(tablename):\n",
        "        # description of table\n",
        "        data['Description'] = rawvals_list[i][0]+rawvals_list[i][1]\n",
        "        # timing data, in milliseconds\n",
        "        j=i+2\n",
        "        time=[]\n",
        "        for k in range(1,len(rawvals_list[j])):\n",
        "          time.append(int(rawvals_list[j][k]))\n",
        "        data['Time'] = time\n",
        "        # strain data, as percent change\n",
        "        j=i+3\n",
        "        cols=len(rawvals_list[j])-1;\n",
        "        rows=16\n",
        "        strain = [[0 for i in range(cols)] for j in range(rows)]\n",
        "        for j in range(i+3,i+19):\n",
        "          segmentNo=int(rawvals_list[j][0])\n",
        "          for k in range(1,len(rawvals_list[j])):\n",
        "            strain[segmentNo-1][k-1]=float(rawvals_list[j][k])\n",
        "        data['Strain'] = strain\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWVvi4_xb1k"
      },
      "source": [
        "### Print Strain Table "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDoOsr66ximQ"
      },
      "source": [
        "def print_table(title,time,strain):\n",
        "  \"\"\"Print formated table of regional strain data.\n",
        "\n",
        "      Parameters:\n",
        "        title (str): description of data\n",
        "        time (list of int): timing of strain curves\n",
        "        strain (list of list of float): strain curves for each regional segment\n",
        "\n",
        "      Returns:\n",
        "        none\n",
        "  \"\"\"\n",
        "  print(title)\n",
        "  print('')\n",
        "\n",
        "  print(\"{:<8}\".format('time (ms)'),end=' ')\n",
        "  for x in range(len(time)):\n",
        "    print(\"{:>7}\".format(time[x]),end='  ')\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  segmentnum=0\n",
        "  for r in range(len(strain)):\n",
        "    segmentnum+=1\n",
        "    print(\"{:<3}\".format('seg'),end=' ')\n",
        "    print(\"{:>2}\".format(segmentnum),end='    ')  \n",
        "    for c in range(len(strain[r])):\n",
        "      print(\"{:>7.3f}\".format(strain[r][c]),end='  ')\n",
        "    print('')\n",
        "  \n",
        "  print('')\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWcJnrMxyC99"
      },
      "source": [
        "### Temporally Align Strain Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekFKld3qyJCn"
      },
      "source": [
        "def temporal_align(strain):\n",
        "  \"\"\"Temporally align regional strain data so that zero strain values occur at \n",
        "     time zero.\n",
        "\n",
        "      Parameters:\n",
        "        strain (list of list of float): strain curves for each regional segment\n",
        "\n",
        "      Returns:\n",
        "        strain (list of list of float): temporally aligned strain curves\n",
        "  \"\"\"\n",
        "\n",
        "  from statistics import mode\n",
        "\n",
        "  offsets = []\n",
        "  for segment in range(len(strain)):\n",
        "    i = [i for i,x in enumerate(strain[segment]) if x==0]  # find indices of zero values\n",
        "    if bool(i):\n",
        "      offsets.append(i[0])  # use index of first zero value only\n",
        "\n",
        "  shift = -mode(offsets)  # shift by most common zero value index\n",
        "\n",
        "  for segment in range(len(strain)):  \n",
        "    strain[segment] = np.ndarray.tolist(np.roll(strain[segment],shift))  # apply shift\n",
        "  \n",
        "  return strain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z-HJGMGym2Z"
      },
      "source": [
        "### Find Peak Strain Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFLd_EPsYJ9_"
      },
      "source": [
        "def time_to_peak(time,strain):\n",
        "  \"\"\"Find time that peak strain occurs.\n",
        "\n",
        "      Parameters:\n",
        "        time (list of int): timing of strain curve\n",
        "        strain (list of float): strain curve\n",
        "\n",
        "      Returns:\n",
        "        tp (float): time of peak strain \n",
        "        ip (float): index of peak strain\n",
        "\n",
        "        tp and ip will be assing nan if strain contains missing values\n",
        "  \"\"\"\n",
        "  if np.any(np.isnan(strain)):\n",
        "    ip = float('nan')\n",
        "    tp = float('nan')\n",
        "  else:\n",
        "    absstrain = [abs(ele) for ele in strain]\n",
        "    ip = absstrain.index(max(absstrain))  # index of peak strain\n",
        "    tp = time[ip]                         # time at peak strain\n",
        "  return tp, ip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o60WSrIpzJbZ"
      },
      "source": [
        "### Calculate Normalized Cross-Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WySagSEYzJba"
      },
      "source": [
        "def normalized_cross_correlation(t,s1,s2,rr):\n",
        "  \"\"\"Calculate normalized cross-correlation between two strain curves.\n",
        "\n",
        "      Parameters:\n",
        "        t (list of int): timing of strain curves\n",
        "        s1 (list of float): strain curve\n",
        "        s2 (list of float): strain curve\n",
        "        rr (int): R-R interval\n",
        "\n",
        "        t, s1 and s2 are assumed to be the same length\n",
        "\n",
        "      Returns:\n",
        "        ncc (list of float): normalized cross-correlation values\n",
        "        lag (list of int): offset applied to s2 \n",
        "        \n",
        "        each element in lag corresponds to elements in ncc\n",
        "  \"\"\"\n",
        "  # normalize signals\n",
        "  ns1 = (s1 - np.mean(s1)) / (np.std(s1) * len(s1))\n",
        "  ns2 = (s2 - np.mean(s2)) / (np.std(s2))\n",
        "  # initalize lists of return values\n",
        "  ncc = []  # normalized cross-correlation\n",
        "  lag = []  # offset lag applied to s2\n",
        "  # calculate correlation for each lag\n",
        "  for shift in range(-int(np.floor((len(t)-1)/2)),int(np.ceil((len(t)-1)/2))+1):\n",
        "    if shift >= 0:\n",
        "      tshift = t[shift]\n",
        "    else:\n",
        "      tshift = t[shift] - rr  # shifts < 0 are equivalent to negative time shifts\n",
        "    lag.append(tshift)\n",
        "    c = np.correlate(ns1,np.roll(ns2,shift),'valid')\n",
        "    ncc.append(c[0])\n",
        "  return ncc, lag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO3oECWbzZOm"
      },
      "source": [
        "### Calculate Cross-Correlation Delay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEMDIFoXzZWr"
      },
      "source": [
        "def cross_correlation_delay(t,s1,s2,rr): \n",
        "  \"\"\"Calculate cross-correlation delay between two strain curves.\n",
        "\n",
        "     Cross-correlation delay is the lag corresponding to largest normalized \n",
        "     cross-correlation value.\n",
        "\n",
        "      Parameters:\n",
        "        t (list of int): timing of strain curves\n",
        "        s1 (list of float): strain curve\n",
        "        s2 (list of float): strain curve\n",
        "        rr (int): R-R interval\n",
        "\n",
        "        t, s1 and s2 are assumed to be the same length\n",
        "\n",
        "      Returns:\n",
        "        ccd (float): cross-correlation delay time\n",
        "        ncc (list of float): normalized cross-correlation values\n",
        "        lag (list of int): offset applied to s2 \n",
        "        \n",
        "        each element in lag corresponds to elements in ncc\n",
        "  \"\"\"\n",
        "  ncc, lag = normalized_cross_correlation(t,s1,s2,rr)\n",
        "  if np.any(np.isnan(ncc)):\n",
        "    ccd = float('nan')\n",
        "  else:\n",
        "    ccd = lag[ncc.index(max(ncc))]  # TODO: verify if this should be ccd = lag[ncc.index(max(np.abs(ncc)))]\n",
        "  return ccd, ncc, lag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvRcs7ZZ2-Mv"
      },
      "source": [
        "### Plot Strain Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVa_CbtUkELF"
      },
      "source": [
        "def plot_strain(data):\n",
        "  \"\"\"Generate figure showing strain curves.\n",
        "\n",
        "      Parameters:\n",
        "        data (dict): dictionary of data with following keys\n",
        "          'Filename' (str): name of source data file\n",
        "          'Description' (str): name of table of regional strain\n",
        "          'Time' (list of int:): timing of strain curves\n",
        "          'Strain' (list of list of floats): strain curves for each regional segment\n",
        "          'Peak Strain Time' (list of int): time that peak strain occurs for each segement\n",
        "      \n",
        "      Returns:\n",
        "        none\n",
        "  \"\"\"\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  nseg = len(data['Strain'])\n",
        "\n",
        "  ncol = 6; # six segments at level basal and mid ventricule \n",
        "  nrow = int(np.ceil(nseg/ncol));\n",
        "\n",
        "  fig, axs = plt.subplots(nrow, ncol, figsize=(12, 8), sharex=True, sharey=True)\n",
        "\n",
        "  for seg in range(nseg):\n",
        "    row = int(np.floor(seg/ncol))\n",
        "    col = seg%ncol\n",
        "    if not np.isnan(data['Peak Strain Time'][seg]):\n",
        "      axs[row,col].scatter(data['Peak Strain Time'][seg],data['Strain'][seg][data['Peak Strain Index'][seg]],label='Peak Strain',marker=\"o\",color='red')\n",
        "    axs[row,col].plot(data['Time'],data['Strain'][seg],label=('Strain'))\n",
        "    axs[row,col].set_title('seg '+str(seg+1))\n",
        "    if row == nrow-1:\n",
        "      axs[row,col].set_xlabel('time (ms)')\n",
        "    if col == 0:\n",
        "      axs[row,col].set_ylabel('strain (%)')\n",
        "    if row == 0 and col == 0:\n",
        "      axs[row,col].legend()\n",
        "    axs[row,col].grid(True)\n",
        "\n",
        "  fig.suptitle(data['Filename']+'\\n'+data['Description'],y=1.05)\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxCV0-8SNWtg"
      },
      "source": [
        "### Print Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IgQWTpxNf5I"
      },
      "source": [
        "def print_results(data):\n",
        "  \"\"\"Print results of synchrony analysis.\n",
        "\n",
        "      Parameters:\n",
        "        data (dict): dictionary of data with following keys\n",
        "          'Filename' (str): name of source data file\n",
        "          'Description' (str): name of table of regional strain\n",
        "          'Time' (list of int:): timing of strain curves\n",
        "          'Strain' (list of list of floats): strain curves for each regional segment\n",
        "          'Peak Strain Time' (list of int): time that peak strain occurs for each segement\n",
        "          'Maximum Difference in Peak Strain Times' (int): as described\n",
        "          'Standard Deviation of Peak Strain Times' (float): as described\n",
        "          'Cross-Correlation Delay Pairs' (list of str): description of pairs of opposing segments\n",
        "          'Cross-Correlation Delays' (list of float): cross-correlation delay for pairs of opposing segments\n",
        "          'Maximum Absolute Cross-Correlation Delay' (float): as described\n",
        "\n",
        "      Returns:\n",
        "        none\n",
        "  \"\"\"\n",
        "  print(data['Description'])\n",
        "  print('')\n",
        "\n",
        "  print(\"{:<21}\".format('Segment Number'),end='  ')\n",
        "  for r in range(len(data['Peak Strain Time'])):\n",
        "    print(\"{:>5}\".format(r+1),end=' ')\n",
        "  print('')\n",
        "  print(\"{:<21}\".format('Peak Strain Time (ms)'),end='  ')\n",
        "  for r in range(len(data['Peak Strain Time'])):\n",
        "    print(\"{:>5}\".format(data['Peak Strain Time'][r]),end=' ')\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  print(\"{:<28}\".format('Segment Pairs'),end='  ')\n",
        "  for r in range(len(data['Cross-Correlation Delay Pairs'])):\n",
        "    print(\"{:>8}\".format(data['Cross-Correlation Delay Pairs'][r]),end=' ')\n",
        "  print('')\n",
        "  print(\"{:<28}\".format('Cross-Correlation Delay (ms)'),end='  ')\n",
        "  for r in range(len(data['Cross-Correlation Delays'])):\n",
        "    print(\"{:>8}\".format(data['Cross-Correlation Delays'][r]),end=' ')\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  print(\"{:<40}\".format('Maximum Difference in Peak Strain Times'),end=' = ')\n",
        "  print(\"{:<}\".format(data['Maximum Difference in Peak Strain Times']),end=' ms')\n",
        "  print('')\n",
        "  print(\"{:<40}\".format('Standard Deviation of Peak Strain Times'),end=' = ')\n",
        "  print(\"{:<.2f}\".format(data['Standard Deviation of Peak Strain Times']),end=' ms')\n",
        "  print('')\n",
        "  print(\"{:<40}\".format('Maximum Absolute Cross-Correlation Delay'),end=' = ')\n",
        "  print(\"{:<}\".format(data['Maximum Absolute Cross-Correlation Delay']),end=' ms')\n",
        "  print('')\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR1dvsbWzJba"
      },
      "source": [
        "## Unit Tests for Cross-Correlation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmt3UL-HzJba"
      },
      "source": [
        "import unittest\n",
        "\n",
        "class TestNormalizedCrossCorrelation(unittest.TestCase):\n",
        "\n",
        "  def test_autocorrelation(self):\n",
        "    '''Test case function for autocorrelation'''\n",
        "    t  = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
        "    rr = 21\n",
        "    s  = [0,1,2,5,9,14,23,31,37,39,36,26,11,11,8,3,1,1,2,2,1]\n",
        "    ncc, lag = normalized_cross_correlation(t,s,s,rr)\n",
        "    result = ncc[lag.index(lag==0)]\n",
        "    expected = 1\n",
        "    self.assertEqual(result, expected)\n",
        "\n",
        "  def test_normalizedcorrelation(self):\n",
        "    '''Test case function for normalized correlation'''\n",
        "    t  = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
        "    rr = 21\n",
        "    s1 = [0,1,2,5,9,14,23,31,37,39,36,26,11,11,8,3,1,1,2,2,1]\n",
        "    s2 = [x*2 for x in s1]\n",
        "    ncc, lag = normalized_cross_correlation(t,s1,s2,rr)\n",
        "    result = ncc[lag.index(lag==0)]\n",
        "    expected = 1\n",
        "    self.assertEqual(result, expected)\n",
        "\n",
        "  def test_lag(self):\n",
        "    '''Test case function for lag'''\n",
        "    t  = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
        "    rr = 21\n",
        "    s1 = [0,1,2,5,9,14,23,31,37,39,36,26,11,11,8,3,1,1,2,2,1]\n",
        "    s2 = [1,0,1,2,5,9,14,23,31,37,39,36,26,11,11,8,3,1,1,2,2]\n",
        "    ncc, lag = normalized_cross_correlation(t,s1,s2,rr)\n",
        "    result = ncc[lag.index(-1)]\n",
        "    expected = 1\n",
        "    self.assertEqual(result, expected)\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwODM948su1e"
      },
      "source": [
        "## Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtKt5WhLsLAB"
      },
      "source": [
        "data = []  # list of dictionaries \n",
        "\n",
        "ventriclename = 'Left Ventricle'\n",
        "\n",
        "for filename in list(uploaded.keys()):\n",
        "\n",
        "  print(filename)\n",
        "  print('')\n",
        "\n",
        "  tablename = 'AHA Diagram Data - 2D Short Axis Results -  Radial Strain (%)'\n",
        "  data.append( parse_data(filename,tablename,ventriclename) )\n",
        "  print_table(data[-1]['Description'],data[-1]['Time'],data[-1]['Strain'])\n",
        "  \n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print('')\n",
        "\n",
        "  print(filename)\n",
        "  print('')\n",
        "\n",
        "  tablename = 'AHA Diagram Data - 2D Short Axis Results -  Circumferential Strain (%)'\n",
        "  data.append( parse_data(filename,tablename,ventriclename) )\n",
        "  print_table(data[-1]['Description'],data[-1]['Time'],data[-1]['Strain'])\n",
        "  \n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print('')\n",
        "\n",
        "  print(filename)\n",
        "  print('')\n",
        "\n",
        "  tablename = 'AHA Diagram Data - 2D Long Axis Results -  Radial Strain (%)'\n",
        "  data.append( parse_data(filename,tablename,ventriclename) )\n",
        "  print_table(data[-1]['Description'],data[-1]['Time'],data[-1]['Strain'])\n",
        "\n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print('')\n",
        "\n",
        "  print(filename)\n",
        "  print('')\n",
        "\n",
        "  tablename = 'AHA Diagram Data - 2D Long Axis Results -  Longitudinal Strain (%)'\n",
        "  data.append( parse_data(filename,tablename,ventriclename) )\n",
        "  print_table(data[-1]['Description'],data[-1]['Time'],data[-1]['Strain'])\n",
        "\n",
        "  if filename != list(uploaded.keys())[-1]:\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7lO0srX1TKJ"
      },
      "source": [
        "## Process Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpONpzMElfGA"
      },
      "source": [
        "Temporally align strain curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKLk1T_2SyNc"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  data[i]['Strain']=temporal_align(data[i]['Strain'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb3j1LTtl6k3"
      },
      "source": [
        "Calculate peak strain time for each strain curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QYZc3yMNQax"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  tpeak = []\n",
        "  indpeak = []\n",
        "  for seg in range(len(data[i]['Strain'])):\n",
        "    t, ind = time_to_peak(data[i]['Time'],data[i]['Strain'][seg])\n",
        "    tpeak.append(t)\n",
        "    indpeak.append(ind)\n",
        "  data[i]['Peak Strain Time'] = tpeak\n",
        "  data[i]['Peak Strain Index'] = indpeak"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbbhvZ_I1fn5"
      },
      "source": [
        "Calculate synchrony metrics\n",
        "\n",
        "1.   maximum difference in time-to-peak strain among any two segments\n",
        "2.   standard deviation of the time-to-peak strain values for all segments \n",
        "3.   max cross-correlation delay between pairs of opposing segments\n",
        "        - basal ventricle: 1v4, 2v5, 3v6\n",
        "        - mid ventricle: 7v10, 8v11, 9v12\n",
        "        - apical ventricle: 13v15, 14v16\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJLmSRVw_Gg"
      },
      "source": [
        "for i in range(len(data)):\n",
        "\n",
        "  # Clear Variables\n",
        "  t, dt, rr, ccd01v04, ccd02v05, ccd03v05, ccd07v10, ccd08v11, ccd09v12, ccd13v15, ccd14v16 = (None,)*11\n",
        "\n",
        "  # Timing Values\n",
        "  t  = data[i]['Time']\n",
        "  dt = np.mean(np.diff(t))  # mean time interval between cardiac phases\n",
        "  rr = int(np.round(t[-1]+dt))  # estimated R-R interval\n",
        "  data[i]['R-R Interval'] = rr \n",
        "\n",
        "  # Calculate Maximum Difference in Peak Strain Times\n",
        "  data[i]['Maximum Difference in Peak Strain Times'] = np.nanmax(data[i]['Peak Strain Time']) - np.nanmin(data[i]['Peak Strain Time'])\n",
        "\n",
        "  # Calculate Standard Deviation of Peak Strain Times\n",
        "  data[i]['Standard Deviation of Peak Strain Times'] = np.nanstd(data[i]['Peak Strain Time'])\n",
        "\n",
        "  # Calculate Cross-Correlation Delay for Basal LV Opposing Pairs\n",
        "  ccd01v04, ncc01v04, lag01v04 = cross_correlation_delay(t,data[i]['Strain'][0],data[i]['Strain'][3],rr)\n",
        "  ccd02v05, ncc02v05, lag02v05 = cross_correlation_delay(t,data[i]['Strain'][1],data[i]['Strain'][4],rr)\n",
        "  ccd03v05, ncc03v06, lag03v06 = cross_correlation_delay(t,data[i]['Strain'][2],data[i]['Strain'][5],rr)\n",
        "\n",
        "  # Calculate Cross-Correlation Delay for Mid LV Opposing Pairs\n",
        "  ccd07v10, ncc07v10, lag07v10 = cross_correlation_delay(t,data[i]['Strain'][6],data[i]['Strain'][9],rr)\n",
        "  ccd08v11, ncc08v11, lag08v11 = cross_correlation_delay(t,data[i]['Strain'][7],data[i]['Strain'][10],rr)\n",
        "  ccd09v12, ncc09v12, lag09v12 = cross_correlation_delay(t,data[i]['Strain'][8],data[i]['Strain'][11],rr)\n",
        "\n",
        "  # Calculate Cross-Correlation Delay for Apical LV Opposing Pairs\n",
        "  ccd13v15, ncc13v15, lag13v15 = cross_correlation_delay(t,data[i]['Strain'][12],data[i]['Strain'][14],rr)\n",
        "  ccd14v16, ncc14v16, lag14v16 = cross_correlation_delay(t,data[i]['Strain'][13],data[i]['Strain'][15],rr)\n",
        "\n",
        "  # Calculate Calculate Maximum Cross-Correlation Delay\n",
        "  data[i]['Cross-Correlation Delays'] = [ccd01v04, ccd02v05, ccd03v05, ccd07v10, ccd08v11, ccd09v12, ccd13v15, ccd14v16]\n",
        "  data[i]['Cross-Correlation Delay Pairs'] = ['01v04', '02v05', '03v05', '07v10', '08v11', '09v12', '13v15', '14v16']\n",
        "  if np.all(np.isnan(data[i]['Cross-Correlation Delays'])):\n",
        "    data[i]['Maximum Absolute Cross-Correlation Delay'] = float('nan')\n",
        "  else:\n",
        "    data[i]['Maximum Absolute Cross-Correlation Delay'] = np.nanmax(np.abs(data[i]['Cross-Correlation Delays']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDvqBJKBTiJE"
      },
      "source": [
        "## Summarize Data and Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwzFinpyTlJA"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  \n",
        "  print(data[i]['Filename'])\n",
        "  print('')\n",
        "\n",
        "  print(data[i]['Description'])\n",
        "  print('')\n",
        "\n",
        "  plot_strain(data[i])\n",
        "  print('')\n",
        "  \n",
        "  print_results(data[i])\n",
        "  print('')\n",
        "\n",
        "  if i < len(data)-1:\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}